{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quran_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5rwqGUpTRyG",
        "outputId": "4540453a-ed65-44cd-8bfd-9492f1cdfdea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('book', quiet=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
        "nltk.download('punkt', quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZfRUO5fTXKv",
        "outputId": "5cd1be53-8f36-4f79-d124-a24fe77450ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from urllib.parse import urlsplit\n",
        "import urllib\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "from google.colab import files\n"
      ],
      "metadata": {
        "id": "h5vYQ36STZRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tagger = nltk.tag.perceptron.PerceptronTagger()\n",
        "\n",
        "def corpus_gen(url, chapter_num): \n",
        "  soup = BeautifulSoup(requests.get(url).text)\n",
        "# print(soup)\n",
        "  quran = [tagger.tag(nltk.word_tokenize(s)) \n",
        "            for p in soup.find_all('p') \n",
        "            for s in nltk.sent_tokenize(p.get_text())]\n",
        "  # for p in soup.find_all('p'):\n",
        "  #   quran.append([tagger.tag(nltk.word_tokenize(s)) \n",
        "  #           for p in section.find_all('p') \n",
        "  #           for s in nltk.sent_tokenize(p.get_text())])\n",
        "\n",
        "  !mkdir -p quran\n",
        "  filename = 'quran/' + 'Chapter' + chapter_num  + '.txt'\n",
        "  with open(filename, 'w') as f:\n",
        "    for s in quran:\n",
        "      for w,t in s:\n",
        "        print(f'{w}_{t}', end=' ', file=f)\n",
        "      print(file=f)\n",
        "  \n",
        "  # files.download(filename)   \n"
      ],
      "metadata": {
        "id": "vZLUPuZvTbA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,115):\n",
        "  if(i<10):\n",
        "    chapter_num = '00'+str(i)\n",
        "  elif(i<100 and i>=10):\n",
        "    chapter_num = '0'+str(i)\n",
        "  elif(i>=100):\n",
        "    chapter_num = str(i)\n",
        "\n",
        "  url = 'https://www.clearquran.com/'+ chapter_num + '.html'\n",
        "  # print(url)   \n",
        "  corpus_gen(url, chapter_num)   "
      ],
      "metadata": {
        "id": "L8NOSLRQTji9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path For Quran Corpus: "
      ],
      "metadata": {
        "id": "aaTrvIW4TmGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/quran/Chapter001.txt')"
      ],
      "metadata": {
        "id": "88H1S-mDiQ0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !fusermount -u drive"
      ],
      "metadata": {
        "id": "DME3OKvtrDl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "\n",
        "!zip -rq quran.zip quran\n",
        "# files.download('example.txt')"
      ],
      "metadata": {
        "id": "6FgcWJmotCaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tagger = nltk.tag.perceptron.PerceptronTagger()\n",
        "\n",
        "\n",
        "!mkdir -p quran_text_only\n",
        "\n",
        "def corpus_gen_text_only(url, chapter_num): \n",
        "  soup = BeautifulSoup(requests.get(url).text)\n",
        "# print(soup)\n",
        "  quran = [tagger.tag(nltk.word_tokenize(s)) \n",
        "            for p in soup.find_all('p') \n",
        "            for s in nltk.sent_tokenize(p.get_text())]\n",
        "  # for p in soup.find_all('p'):\n",
        "  #   quran.append([tagger.tag(nltk.word_tokenize(s)) \n",
        "  #           for p in section.find_all('p') \n",
        "  #           for s in nltk.sent_tokenize(p.get_text())])\n",
        "\n",
        "  filename = 'quran_text_only/' + 'Chapter' + chapter_num  + '.txt'\n",
        "  with open(filename, 'w') as f:\n",
        "    for s in quran:\n",
        "      for w,t in s:\n",
        "        print(f'{w}', end=' ', file=f)\n",
        "      print(file=f)\n",
        "  \n",
        "  # files.download(filename)  \n",
        "\n",
        "for i in range(1,115):\n",
        "  if(i<10):\n",
        "    chapter_num = '00'+str(i)\n",
        "  elif(i<100 and i>=10):\n",
        "    chapter_num = '0'+str(i)\n",
        "  elif(i>=100):\n",
        "    chapter_num = str(i)\n",
        "\n",
        "  url = 'https://www.clearquran.com/'+ chapter_num + '.html'\n",
        "  # print(url)   \n",
        "  corpus_gen_text_only(url, chapter_num)   \n",
        "\n",
        "\n",
        "!zip -rq quran_text_only.zip quran_text_only"
      ],
      "metadata": {
        "id": "w-bMSYN7wd9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wGPWJSocYWJz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}